{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full `causal-curve` tutorial: analyzing the causal impact of reducing blood lead levels in children on achievement and cognitive scores\n",
    "All NHANES III data obtained here: https://wwwn.cdc.gov/nchs/nhanes/nhanes3/datafiles.aspx#core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Mediation' from 'causal_curve' (/Users/ronik/.pyenv/versions/ADRF/lib/python3.7/site-packages/causal_curve/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e8bda62652e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcausal_curve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcausal_curve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMediation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Mediation' from 'causal_curve' (/Users/ronik/.pyenv/versions/ADRF/lib/python3.7/site-packages/causal_curve/__init__.py)"
     ]
    }
   ],
   "source": [
    "from os.path import expanduser\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from causal_curve import GPS\n",
    "from causal_curve import Mediation\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = [5, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Household Youth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of columns in ASCII text file\n",
    "cols = [\n",
    "    (0,5), # Sequence number, SEQN, columns 1-5, page \n",
    "    (5,10), # Family sequence number, DMPFSEQ, columns 6-10, page\n",
    "    (10,11), # Examination/interview status, DMPSTAT, columns 11, page \n",
    "    (11,12), # Race-ethnicity, DMARETHN, columns 12, page\n",
    "    (12,13), # Race, DMARACER, columns 13, page\n",
    "    (13,14), # Ethnicity, DMAETHNR, columns 14, page\n",
    "    (14,15), # Sex, HSSEX, columns 15, page\n",
    "    (20,24), # Age in months, HSAITMOR, columns 21-24, page \n",
    "    (35,41), # Poverty Income Ratio, DMPPIR, columns 36-41, page \n",
    "    (1291,1292), # persons who smoke cigarettes in home, HFF1, columns 1292, page \n",
    "    (1312,1313), # Do you have enough food to eat, sometimes not enough to eat, or often not enough to eat?, HFF4, columns 1313, page \n",
    "    (1358,1360), # Highest grade or yr of school completed, HFHEDUCR, columns 1359-1360, page \n",
    "    (1378,1379), # Did mother smoke while pregnant with SP, HYA3, columns 1379, page\n",
    "    (1382,1383), # Did SP receive newborn intensive care, HYA6, columns 1383, page\n",
    "]\n",
    "\n",
    "column_names = [\n",
    "    'SEQN',\n",
    "    'FAMILY_SEQN',\n",
    "    'STATUS',\n",
    "    'RACE_ETH',\n",
    "    'RACE',\n",
    "    'ETH',\n",
    "    'SEX',\n",
    "    'AGE',\n",
    "    'PIR',\n",
    "    'SMOKE_HOME',\n",
    "    'FOOD',\n",
    "    'EDU',\n",
    "    'SMOKE_PREG',\n",
    "    'BABY_NICU'\n",
    "]\n",
    "\n",
    "raw_youth_file = []\n",
    "with open(expanduser('~/Desktop/NHANES_III/youth.dat'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        raw_youth_file.append([line[c[0]:c[1]] for c in cols])\n",
    "\n",
    "f.close()\n",
    "\n",
    "raw_youth_df = pd.DataFrame(raw_youth_file, columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examination Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO PARSE THIS ASCII FILE\n",
    "# See: https://stackoverflow.com/questions/45286642/reading-values-from-a-text-file-using-specific-column-numbers-in-python\n",
    "\n",
    "# Location of columns\n",
    "cols = [\n",
    "    (0,5), # Sequence number, SEQN, columns 1-5, page \n",
    "    (5,10), # Family sequence number, DMPFSEQ, columns 6-10, page\n",
    "    (10,11), # Examination/interview status, DMPSTAT, columns 11, page \n",
    "    (4432,4434), # WISC/WRAT Math scaled score, WWPMSCSR, columns 4433-4434, page\n",
    "    (4434, 4436), # WISC/WRAT Reading scaled score, WWPRSCSR, columns 4435-4436, page\n",
    "    (4436, 4438), # WISC/WRAT Block design scaled score, WWPBSCSR, columns 4437-4438, page\n",
    "    (4438, 4440) # WISC/WRAT Digit span scaled score, WWPDSCSR, columns 4439-4440, page\n",
    "]\n",
    "\n",
    "column_names = [\n",
    "    'SEQN',\n",
    "    'FAMILY_SEQN',\n",
    "    'STATUS',\n",
    "    'MATH',\n",
    "    'READING',\n",
    "    'BLOCK',\n",
    "    'DIGIT'\n",
    "]\n",
    "\n",
    "raw_exam_file = []\n",
    "with open(expanduser('~/Desktop/NHANES_III/exam.dat'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        raw_exam_file.append([line[c[0]:c[1]] for c in cols])\n",
    "\n",
    "f.close()\n",
    "\n",
    "raw_exam_df = pd.DataFrame(raw_exam_file, columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laboratory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO PARSE THIS ASCII FILE\n",
    "# See: https://stackoverflow.com/questions/45286642/reading-values-from-a-text-file-using-specific-column-numbers-in-python\n",
    "\n",
    "# Location of columns\n",
    "cols = [\n",
    "    (0,5), # Sequence number, SEQN, columns 1-5, page \n",
    "    (5,10), # Family sequence number, DMPFSEQ, columns 6-10, page\n",
    "    (10,11), # Examination/interview status, DMPSTAT, columns 11, page \n",
    "    (1422,1426), # Lead (ug/dL), PBP, columns 1423-1426, page  \n",
    "]\n",
    "\n",
    "column_names = [\n",
    "    'SEQN',\n",
    "    'FAMILY_SEQN',\n",
    "    'STATUS',\n",
    "    'BLL'\n",
    "]\n",
    "\n",
    "raw_lab_file = []\n",
    "with open(expanduser('~/Desktop/NHANES_III/lab.dat'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        raw_lab_file.append([line[c[0]:c[1]] for c in cols])\n",
    "\n",
    "f.close()\n",
    "\n",
    "raw_lab_df = pd.DataFrame(raw_lab_file, columns = column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge these together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_merged_df = raw_youth_df.merge(\n",
    "    raw_exam_df.drop(['FAMILY_SEQN', 'STATUS'], axis = 1), how = \"left\", on = \"SEQN\"\n",
    ").merge(\n",
    "    raw_lab_df.drop(['FAMILY_SEQN', 'STATUS'], axis = 1), how = \"left\", on = \"SEQN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column formatting and some subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATUS\n",
    "raw_merged_df['STATUS'] =  raw_merged_df['STATUS'].str.replace(\"1\", \"No_exam\")\n",
    "raw_merged_df['STATUS'] =  raw_merged_df['STATUS'].str.replace(\"2\", \"MEC_exam\")\n",
    "raw_merged_df['STATUS'] =  raw_merged_df['STATUS'].str.replace(\"3\", \"Home_exam\")\n",
    "\n",
    "# RACE_ETH\n",
    "raw_merged_df['RACE_ETH'] =  raw_merged_df['RACE_ETH'].str.replace(\"1\", \"NH_White\")\n",
    "raw_merged_df['RACE_ETH'] =  raw_merged_df['RACE_ETH'].str.replace(\"2\", \"NH_Black\")\n",
    "raw_merged_df['RACE_ETH'] =  raw_merged_df['RACE_ETH'].str.replace(\"3\", \"Mex_Am\")\n",
    "raw_merged_df['RACE_ETH'] =  raw_merged_df['RACE_ETH'].str.replace(\"4\", \"Other\")\n",
    "\n",
    "# RACE\n",
    "raw_merged_df['RACE'] =  raw_merged_df['RACE'].str.replace(\"1\", \"White\")\n",
    "raw_merged_df['RACE'] =  raw_merged_df['RACE'].str.replace(\"2\", \"Black\")\n",
    "raw_merged_df['RACE'] =  raw_merged_df['RACE'].str.replace(\"3\", \"Other\")\n",
    "raw_merged_df['RACE'] =  raw_merged_df['RACE'].str.replace(\"8\", \"Mex_Am\")\n",
    "\n",
    "# ETH\n",
    "raw_merged_df['ETH'] =  raw_merged_df['ETH'].str.replace(\"1\", \"Mex_Am\")\n",
    "raw_merged_df['ETH'] =  raw_merged_df['ETH'].str.replace(\"2\", \"Other_Hisp\")\n",
    "raw_merged_df['ETH'] =  raw_merged_df['ETH'].str.replace(\"3\", \"Not_Hisp\")\n",
    "\n",
    "# SEX\n",
    "raw_merged_df['SEX'] =  raw_merged_df['SEX'].str.replace(\"1\", \"Male\")\n",
    "raw_merged_df['SEX'] =  raw_merged_df['SEX'].str.replace(\"2\", \"Female\")\n",
    "\n",
    "# AGE\n",
    "raw_merged_df['AGE'] = raw_merged_df['AGE'].astype(float) / 12\n",
    "\n",
    "# PIR\n",
    "raw_merged_df['PIR'] = raw_merged_df['PIR'].astype(float) \n",
    "raw_merged_df['PIR'][raw_merged_df['PIR'] == 888888.000] = np.nan\n",
    "\n",
    "# EDU\n",
    "raw_merged_df['EDU'] = raw_merged_df['EDU'].astype(int)\n",
    "raw_merged_df['EDU'][raw_merged_df['EDU'] == 88] = None\n",
    "raw_merged_df['EDU'][raw_merged_df['EDU'] == 99] = None\n",
    "\n",
    "raw_merged_df['EDU_CAT'] = np.where(raw_merged_df['EDU'] < 9, 'LT_HS', \n",
    "    np.where(\n",
    "        ((raw_merged_df['EDU'] >= 9) & (raw_merged_df['EDU'] < 12)), 'HS', \n",
    "        np.where(raw_merged_df['EDU'] == 12, 'GRAD_HS', None)\n",
    "    )\n",
    ")\n",
    "\n",
    "# SMOKE_HOME\n",
    "raw_merged_df['SMOKE_HOME'] = raw_merged_df['SMOKE_HOME'].str.replace(\"1\", \"Yes\")\n",
    "raw_merged_df['SMOKE_HOME'] = raw_merged_df['SMOKE_HOME'].str.replace(\"2\", \"No\")\n",
    "raw_merged_df['SMOKE_HOME'] = raw_merged_df['SMOKE_HOME'].str.replace(\"8\", \"None\")\n",
    "\n",
    "# FOOD\n",
    "raw_merged_df['FOOD'] = raw_merged_df['FOOD'].str.replace(\"1\", \"Good\")\n",
    "raw_merged_df['FOOD'] = raw_merged_df['FOOD'].str.replace(\"2\", \"Sometimes_bad\")\n",
    "raw_merged_df['FOOD'] = raw_merged_df['FOOD'].str.replace(\"3\", \"Often_bad\")\n",
    "raw_merged_df['FOOD'] = raw_merged_df['FOOD'].str.replace(\"8\", \"None\")\n",
    "\n",
    "# SMOKE_PREG\n",
    "raw_merged_df['SMOKE_PREG'] = raw_merged_df['SMOKE_PREG'].str.replace(\"1\", \"Yes\")\n",
    "raw_merged_df['SMOKE_PREG'] = raw_merged_df['SMOKE_PREG'].str.replace(\"2\", \"No\")\n",
    "raw_merged_df['SMOKE_PREG'] = raw_merged_df['SMOKE_PREG'].str.replace(\"8\", \"None\")\n",
    "raw_merged_df['SMOKE_PREG'] = raw_merged_df['SMOKE_PREG'].str.replace(\" \", \"None\")\n",
    "\n",
    "# BABY_NICU\n",
    "raw_merged_df['BABY_NICU'] = raw_merged_df['BABY_NICU'].str.replace(\"1\", \"Yes\")\n",
    "raw_merged_df['BABY_NICU'] = raw_merged_df['BABY_NICU'].str.replace(\"2\", \"No\")\n",
    "raw_merged_df['BABY_NICU'] = raw_merged_df['BABY_NICU'].str.replace(\"8\", \"None\")\n",
    "raw_merged_df['BABY_NICU'] = raw_merged_df['BABY_NICU'].str.replace(\"9\", \"None\")\n",
    "raw_merged_df['BABY_NICU'] = raw_merged_df['BABY_NICU'].str.replace(\" \", \"None\")\n",
    "\n",
    "# Drop Nans at this point\n",
    "raw_merged_df = raw_merged_df.dropna()\n",
    "\n",
    "# MATH\n",
    "raw_merged_df['MATH'] = raw_merged_df['MATH'].str.replace(\"NaN\", \"\")\n",
    "raw_merged_df['MATH'] = raw_merged_df['MATH'].str.replace(\" \", \"\")\n",
    "raw_merged_df['MATH'] = raw_merged_df['MATH'].str.replace(\"88\", \"\")\n",
    "raw_merged_df = raw_merged_df[raw_merged_df['MATH'] != '']\n",
    "raw_merged_df['MATH'] = raw_merged_df['MATH'].astype(float)\n",
    "\n",
    "# READING\n",
    "raw_merged_df['READING'] = raw_merged_df['READING'].str.replace(\"NaN\", \"\")\n",
    "raw_merged_df['READING'] = raw_merged_df['READING'].str.replace(\" \", \"\")\n",
    "raw_merged_df['READING'] = raw_merged_df['READING'].str.replace(\"88\", \"\")\n",
    "raw_merged_df = raw_merged_df[raw_merged_df['READING'] != '']\n",
    "raw_merged_df['READING'] = raw_merged_df['READING'].astype(float)\n",
    "\n",
    "# BLOCK\n",
    "raw_merged_df['BLOCK'] = raw_merged_df['BLOCK'].str.replace(\"NaN\", \"\")\n",
    "raw_merged_df['BLOCK'] = raw_merged_df['BLOCK'].str.replace(\" \", \"\")\n",
    "raw_merged_df['BLOCK'] = raw_merged_df['BLOCK'].str.replace(\"88\", \"\")\n",
    "raw_merged_df = raw_merged_df[raw_merged_df['BLOCK'] != '']\n",
    "raw_merged_df['BLOCK'] = raw_merged_df['BLOCK'].astype(float)\n",
    "\n",
    "# DIGIT\n",
    "raw_merged_df['DIGIT'] = raw_merged_df['DIGIT'].str.replace(\"NaN\", \"\")\n",
    "raw_merged_df['DIGIT'] = raw_merged_df['DIGIT'].str.replace(\" \", \"\")\n",
    "raw_merged_df['DIGIT'] = raw_merged_df['DIGIT'].str.replace(\"88\", \"\")\n",
    "raw_merged_df = raw_merged_df[raw_merged_df['DIGIT'] != '']\n",
    "raw_merged_df['DIGIT'] = raw_merged_df['DIGIT'].astype(float)\n",
    "\n",
    "# BLL\n",
    "raw_merged_df = raw_merged_df[raw_merged_df['BLL'] != '']\n",
    "raw_merged_df = raw_merged_df[raw_merged_df['BLL'] != '8888']\n",
    "raw_merged_df['BLL'] = raw_merged_df['BLL'].str.replace(\"000\", \"\")\n",
    "raw_merged_df['BLL'] = raw_merged_df['BLL'].str.replace(\"00\", \"0\")\n",
    "raw_merged_df['BLL'] = raw_merged_df['BLL'].str.lstrip(\"0\")\n",
    "raw_merged_df['BLL'] = raw_merged_df['BLL'].astype(float, errors = 'ignore')  \n",
    "raw_merged_df['BLL'] = raw_merged_df['BLL'].str.replace(\".7\", \"0.7\")\n",
    "raw_merged_df['BLL'] = raw_merged_df['BLL'].str.replace(\"    \", \"\")\n",
    "\n",
    "raw_merged_df['BLL'] = pd.to_numeric(raw_merged_df['BLL'], errors = 'coerce')\n",
    "\n",
    "# Once again, remove any 'None' values\n",
    "raw_merged_df = raw_merged_df.dropna()\n",
    "\n",
    "raw_merged_df = raw_merged_df[\n",
    "    ((raw_merged_df['SMOKE_HOME'] != 'None') & (raw_merged_df['FOOD'] != 'None') & (raw_merged_df['SMOKE_PREG'] != 'None') & (raw_merged_df['BABY_NICU'] != 'None'))\n",
    "]\n",
    "\n",
    "format_merged_df = raw_merged_df.drop(['FAMILY_SEQN', 'STATUS', 'RACE', 'ETH', 'EDU'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making dummy vars, prepping for causal inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(\n",
    "    [\n",
    "        pd.get_dummies(format_merged_df[\"RACE_ETH\"], prefix='Race', drop_first=True),\n",
    "        pd.get_dummies(format_merged_df[\"EDU_CAT\"], prefix='Edu', drop_first=True),\n",
    "        pd.get_dummies(format_merged_df[\"SEX\"], prefix='Sex', drop_first=True),\n",
    "        format_merged_df['AGE'].rename('Age'),\n",
    "        format_merged_df['PIR'].rename('PIR'),\n",
    "        pd.get_dummies(format_merged_df[\"SMOKE_HOME\"], prefix='Smoke_Home', drop_first=True),\n",
    "        pd.get_dummies(format_merged_df[\"FOOD\"], prefix='Food', drop_first=True),\n",
    "        pd.get_dummies(format_merged_df[\"SMOKE_PREG\"], prefix='Smoke_Preg', drop_first=True),\n",
    "        pd.get_dummies(format_merged_df[\"BABY_NICU\"], prefix='Baby_NICU', drop_first=True),\n",
    "        format_merged_df['MATH'].rename('Math'),\n",
    "        format_merged_df['READING'].rename('Reading'),\n",
    "        format_merged_df['BLOCK'].rename('Block'),\n",
    "        format_merged_df['DIGIT'].rename('Digit'),\n",
    "        format_merged_df['BLL']\n",
    "    ]\n",
    "    , axis = 1\n",
    ")\n",
    "\n",
    "\n",
    "# Let's only focus on BLLs less than 25 mg/dL. Anything above 5 mg/dL is considered elevated.\n",
    "final_df = final_df[final_df['BLL'] <= 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the key distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blood lead levels are log-normally distributed (an expected result...)\n",
    "\n",
    "ax = plt.subplot(111)  \n",
    "final_df['BLL'].plot.hist(bins = 30, rwidth=0.9, color = 'steelblue')\n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False)  \n",
    "ax.get_xaxis().tick_bottom()  \n",
    "ax.get_yaxis().tick_left()\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('Blood lead (ug/dL)')\n",
    "ax.set_title(\"Blood lead distribution\", fontsize = 11)\n",
    "plt.tight_layout()\n",
    "plt.savefig('BLL_dist.png', bbox_inches='tight', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See distribution of the scaled test scores\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "final_df['Math'].plot.hist(ax=axs[0,0], bins = 15, rwidth=0.9, color = 'steelblue')\n",
    "final_df['Reading'].plot.hist(ax=axs[0,1], bins = 15, rwidth=0.9, color = 'steelblue')\n",
    "final_df['Block'].plot.hist(ax=axs[1,0], bins = 15, rwidth=0.9, color = 'steelblue')\n",
    "final_df['Digit'].plot.hist(ax=axs[1,1], bins = 15, rwidth=0.9, color = 'steelblue')\n",
    "axs[0,0].set_ylabel('Frequency')\n",
    "axs[0,1].set_ylabel('')\n",
    "axs[1,0].set_ylabel('Frequency')\n",
    "axs[1,1].set_ylabel('')\n",
    "axs[1,0].set_xlabel('Blood Lead (ug/dL)')\n",
    "axs[1,1].set_xlabel('Blood Lead (ug/dL)')\n",
    "axs[0,0].set_title(\"Math\", fontsize = 8)\n",
    "axs[0,1].set_title(\"Reading\", fontsize = 8)\n",
    "axs[1,0].set_title(\"Block\", fontsize = 8)\n",
    "axs[1,1].set_title(\"Digit\", fontsize = 8)\n",
    "\n",
    "for i in [0,1]:\n",
    "    for j in [0,1]:\n",
    "        axs[i,j].spines[\"top\"].set_visible(False)\n",
    "        axs[i,j].spines[\"right\"].set_visible(False)\n",
    "        axs[i,j].tick_params(axis='both', which='major', labelsize=6)\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.suptitle(\"Distributions of scaled test scores\", fontsize = 10)\n",
    "fig.savefig('test_dist.png', bbox_inches='tight', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform causal inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store model results\n",
    "results_dict = {}\n",
    "\n",
    "# Potential confounders\n",
    "potential_confounders = [\n",
    "    'Age', 'Sex_Male', 'Race_NH_Black', 'Race_NH_White', 'Race_Other', \n",
    "    'Edu_HS', 'Edu_LT_HS', 'Smoke_Home_Yes', 'Baby_NICU_Yes', 'Food_Often_bad', 'Food_Sometimes_bad'\n",
    "]\n",
    "\n",
    "\n",
    "# Try the MATH model\n",
    "math_gps = GPS(gps_family='normal', lower_grid_constraint = 0.0, upper_grid_constraint = 0.99, n_splines=10, verbose=False)\n",
    "math_gps.fit(\n",
    "    T=final_df['BLL'], \n",
    "    X=final_df[potential_confounders], \n",
    "    y=final_df['Math']\n",
    ")\n",
    "\n",
    "results_dict['math_CDRC'] = math_gps.calculate_CDRC()\n",
    "\n",
    "\n",
    "# Try the READING model\n",
    "reading_gps = GPS(gps_family='normal', lower_grid_constraint = 0.0, upper_grid_constraint = 0.99, n_splines=10, verbose=False)\n",
    "\n",
    "reading_gps.fit(\n",
    "    T=final_df['BLL'], \n",
    "    X=final_df[potential_confounders],  \n",
    "    y=final_df['Reading']\n",
    ")\n",
    "\n",
    "results_dict['reading_CDRC'] = reading_gps.calculate_CDRC()\n",
    "\n",
    "\n",
    "\n",
    "# Try the Block model\n",
    "block_gps = GPS(gps_family='normal', lower_grid_constraint = 0.0, upper_grid_constraint = 0.99, n_splines=10, verbose=False)\n",
    "\n",
    "block_gps.fit(\n",
    "    T=final_df['BLL'], \n",
    "    X=final_df[potential_confounders],  \n",
    "    y=final_df['Block']\n",
    ")\n",
    "\n",
    "results_dict['block_CDRC'] = block_gps.calculate_CDRC()\n",
    "\n",
    "\n",
    "\n",
    "# Try the Digit model\n",
    "digit_gps = GPS(gps_family='normal', lower_grid_constraint = 0.0, upper_grid_constraint = 0.99, n_splines=10, verbose=False)\n",
    "\n",
    "digit_gps.fit(\n",
    "    T=final_df['BLL'], \n",
    "    X=final_df[potential_confounders],  \n",
    "    y=final_df['Digit']\n",
    ")\n",
    "\n",
    "results_dict['digit_CDRC'] = digit_gps.calculate_CDRC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot causal inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_class = [['math_CDRC', 'reading_CDRC'], ['block_CDRC', 'digit_CDRC']]\n",
    "\n",
    "result_name = [['Math', 'Reading'], ['Block Design', 'Digit Spanning']]\n",
    "\n",
    "def plot_mean_and_CI(axs, i, j, treatment, mean, lb, ub, color_mean=None, color_shading=None):\n",
    "    # plot the shaded range of the confidence intervals\n",
    "    axs[i,j].fill_between(treatment, lb, ub, color=color_shading, alpha=0.3)\n",
    "    # plot the mean on top\n",
    "    axs[i,j].plot(treatment, mean, color_mean, linewidth=0.75)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = [6, 5]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "for i in [0,1]:\n",
    "    for j in [0,1]:\n",
    "\n",
    "        # Plotting quantities\n",
    "        treat = results_dict[result_class[i][j]]['Treatment']\n",
    "        mean = results_dict[result_class[i][j]]['CDRC']\n",
    "        lb = results_dict[result_class[i][j]]['Lower_CI']\n",
    "        ub = results_dict[result_class[i][j]]['Upper_CI']\n",
    "        plot_mean_and_CI(axs, i, j, treat, mean, lb, ub, color_mean='b', color_shading='b')\n",
    "\n",
    "        # Labels\n",
    "        axs[0,0].set_ylabel('Scaled Test Score', fontsize = 8)\n",
    "        axs[0,1].set_ylabel('')\n",
    "        axs[1,0].set_ylabel('Scaled Test Score', fontsize = 8)\n",
    "        axs[1,1].set_ylabel('')\n",
    "        axs[1,0].set_xlabel('Blood Lead (ug/dL)', fontsize = 8)\n",
    "        axs[1,1].set_xlabel('Blood Lead (ug/dL)', fontsize = 8)\n",
    "\n",
    "        axs[i,j].set_title(result_name[i][j], fontsize = 8)\n",
    "        axs[i,j].set_title(result_name[i][j], fontsize = 8)\n",
    "        axs[i,j].set_title(result_name[i][j], fontsize = 8)\n",
    "        axs[i,j].set_title(result_name[i][j], fontsize = 8)\n",
    "\n",
    "        axs[i,j].spines[\"top\"].set_visible(False)\n",
    "        axs[i,j].spines[\"right\"].set_visible(False)\n",
    "\n",
    "        axs[i,j].set_xlim(0, 10)\n",
    "        axs[i,j].set_ylim(0, 15)\n",
    "        \n",
    "        axs[i,j].tick_params(axis='both', which='major', labelsize=6)\n",
    "\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.suptitle(\"Test Performance Causal Curves (with 95% CIs)\", fontsize = 10)\n",
    "fig.savefig('test_causal_curves.png', bbox_inches='tight', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring how BLLs mediate the relationship between income and cognitive outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADRF",
   "language": "python",
   "name": "adrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
